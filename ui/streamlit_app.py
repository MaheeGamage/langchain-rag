# streamlit_app.py
#
# Pure presentation layer â€” all RAG work happens via the FastAPI backend.
# Run with:  streamlit run ui/streamlit_app.py

import os
import streamlit as st
import requests

# â”€â”€ API base URL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# In Docker: API_URL=http://api:8000  (service-to-service).
# Locally:   defaults to http://localhost:8000.
API_URL = os.getenv("API_URL", "http://localhost:8000")


# â”€â”€ API helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _get_config() -> dict:
    """Fetch model info from the API. Returns empty dict on failure."""
    try:
        resp = requests.get(f"{API_URL}/config", timeout=5)
        resp.raise_for_status()
        return resp.json()
    except Exception:
        return {}


def _query_api(question: str) -> dict:
    """Send a question to the /query endpoint and return the JSON response."""
    resp = requests.post(
        f"{API_URL}/query",
        json={"question": question},
        timeout=120,
    )
    resp.raise_for_status()
    return resp.json()


# â”€â”€ Page config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="RAG Chat",
    page_icon="ðŸ”",
    layout="centered",
)

# â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
api_config = _get_config()

with st.sidebar:
    st.title("RAG Chat")
    st.caption("Ask questions about your ingested documents.")

    st.divider()

    if api_config:
        st.markdown("**Models**")
        st.markdown(f"- LLM: `{api_config.get('llm_model', '?')}`")
        st.markdown(f"- Embeddings: `{api_config.get('embedding_model', '?')}`")
    else:
        st.warning("API not reachable")

    st.divider()

    if st.button("Clear chat history", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# â”€â”€ Session state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Each message: {"role": "user"|"assistant", "content": str, "sources": list}
if "messages" not in st.session_state:
    st.session_state.messages = []


# â”€â”€ Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _render_sources(sources: list[dict]) -> None:
    """Render retrieved source documents inside an expander."""
    with st.expander(f"ðŸ“„ Sources ({len(sources)} chunks)", expanded=False):
        for i, src in enumerate(sources, start=1):
            meta = src.get("metadata", {})
            source = meta.get("source", "Unknown")
            page = meta.get("page")
            label = f"**[{i}]** {source}"
            if page is not None:
                label += f" â€” page {int(page) + 1}"
            st.markdown(label)
            st.caption(src.get("content", "")[:400])
            if i < len(sources):
                st.divider()


# â”€â”€ Page header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.header("ðŸ” RAG Chat", divider="gray")

# â”€â”€ Render chat history â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

        # Show source documents for assistant messages
        if msg["role"] == "assistant" and msg.get("sources"):
            _render_sources(msg["sources"])

# â”€â”€ Chat input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if prompt := st.chat_input("Ask a question about your documentsâ€¦"):

    # 1. Store & display user message
    st.session_state.messages.append({"role": "user", "content": prompt, "sources": []})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. Call the API and display the answer
    with st.chat_message("assistant"):
        with st.spinner("Retrieving and generatingâ€¦"):
            try:
                result = _query_api(prompt)
                answer = result.get("answer", "No answer returned.")
                sources = result.get("sources", [])
            except requests.exceptions.ConnectionError:
                answer = "âš ï¸ Could not connect to the API. Is the server running?"
                sources = []
            except Exception as e:
                answer = f"âš ï¸ API error: {e}"
                sources = []

        st.markdown(answer)
        if sources:
            _render_sources(sources)

    # 3. Persist assistant message to history
    st.session_state.messages.append({
        "role": "assistant",
        "content": answer,
        "sources": sources,
    })
