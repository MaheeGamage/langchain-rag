# Copy this file to .env and fill in the values.
# LLM_PROVIDER and EMBEDDING_PROVIDER are fully independent — mix any combination.

# ── Provider switches ─────────────────────────────────────────────────────────
# Supported: ollama | openai | gemini
LLM_PROVIDER=ollama
EMBEDDING_PROVIDER=ollama

# ── Example: cheap local embeddings + cloud LLM ───────────────────────────────
# LLM_PROVIDER=gemini
# EMBEDDING_PROVIDER=ollama

# ── Ollama ────────────────────────────────────────────────────────────────────
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_LLM_MODEL=tinyllama
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# ── OpenAI ────────────────────────────────────────────────────────────────────
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_LLM_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_BASE_URL=   # optional: Azure / proxy endpoint

# ── Google Gemini ─────────────────────────────────────────────────────────────
GEMINI_API_KEY=your-google-api-key-here
GEMINI_LLM_MODEL=gemini-2.5-flash
GEMINI_EMBEDDING_MODEL=gemini-embedding-001
